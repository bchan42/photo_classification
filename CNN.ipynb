{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess / Load / Split Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Path</th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>datasets/Alex/Alex-Image119.png</td>\n",
       "      <td>Alex</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>datasets/Alex/Alex-Image131.png</td>\n",
       "      <td>Alex</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>datasets/Alex/Alex-Image125.png</td>\n",
       "      <td>Alex</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>datasets/Alex/Alex-Image247.png</td>\n",
       "      <td>Alex</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>datasets/Alex/Alex-Image27.png</td>\n",
       "      <td>Alex</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              Path Target\n",
       "0  datasets/Alex/Alex-Image119.png   Alex\n",
       "1  datasets/Alex/Alex-Image131.png   Alex\n",
       "2  datasets/Alex/Alex-Image125.png   Alex\n",
       "3  datasets/Alex/Alex-Image247.png   Alex\n",
       "4   datasets/Alex/Alex-Image27.png   Alex"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('labelled_images.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X: (485, 128, 128, 3), Shape of y: (485,)\n"
     ]
    }
   ],
   "source": [
    "# Function to load and preprocess images\n",
    "def preprocess_images(df, target_size=(128, 128)):\n",
    "    images = []\n",
    "    labels = []\n",
    "    \n",
    "    for index, row in df.iterrows():\n",
    "        # Load image and resize\n",
    "        image = load_img(row['Path'], target_size=target_size)\n",
    "        image = img_to_array(image)  # Convert to numpy array\n",
    "        image = image / 255.0  # Normalize pixel values to [0, 1]\n",
    "        \n",
    "        # Append the image and its corresponding label\n",
    "        images.append(image)\n",
    "        labels.append(row['Target'])\n",
    "\n",
    "    return np.array(images), np.array(labels)\n",
    "\n",
    "X, y = preprocess_images(df)\n",
    "print(f\"Shape of X: {X.shape}, Shape of y: {y.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set shape: (388, 128, 128, 3), (388,)\n",
      "Test set shape: (97, 128, 128, 3), (97,)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(f\"Training set shape: {X_train.shape}, {y_train.shape}\")\n",
    "print(f\"Test set shape: {X_test.shape}, {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoded training labels: [1 0 0 0 1 1 0 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "# Encode labels (Alex -> 0, Kelly -> 1)\n",
    "label_encoder = LabelEncoder()\n",
    "y_train_encoded = label_encoder.fit_transform(y_train)\n",
    "y_test_encoded = label_encoder.transform(y_test)\n",
    "\n",
    "# Check the encoded labels\n",
    "print(f\"Encoded training labels: {y_train_encoded[:10]}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional Neural Network (Images Only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 169ms/step - accuracy: 0.5208 - loss: 0.9808 - val_accuracy: 0.4742 - val_loss: 0.6966\n",
      "Epoch 2/10\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 153ms/step - accuracy: 0.5325 - loss: 0.6755 - val_accuracy: 0.5979 - val_loss: 0.6596\n",
      "Epoch 3/10\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 149ms/step - accuracy: 0.6213 - loss: 0.6271 - val_accuracy: 0.7113 - val_loss: 0.6255\n",
      "Epoch 4/10\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 136ms/step - accuracy: 0.7129 - loss: 0.5882 - val_accuracy: 0.5773 - val_loss: 0.7092\n",
      "Epoch 5/10\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 160ms/step - accuracy: 0.7601 - loss: 0.5308 - val_accuracy: 0.6804 - val_loss: 0.6408\n",
      "Epoch 6/10\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 142ms/step - accuracy: 0.8600 - loss: 0.3840 - val_accuracy: 0.5979 - val_loss: 0.7400\n",
      "Epoch 7/10\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 136ms/step - accuracy: 0.8615 - loss: 0.3603 - val_accuracy: 0.6186 - val_loss: 0.7345\n",
      "Epoch 8/10\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 140ms/step - accuracy: 0.8921 - loss: 0.3011 - val_accuracy: 0.6701 - val_loss: 0.7858\n",
      "Epoch 9/10\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 137ms/step - accuracy: 0.9170 - loss: 0.2241 - val_accuracy: 0.5979 - val_loss: 0.9080\n",
      "Epoch 10/10\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 139ms/step - accuracy: 0.9449 - loss: 0.1657 - val_accuracy: 0.6907 - val_loss: 0.7879\n",
      "Final Training Accuracy: 0.9381\n",
      "Final Validation Accuracy: 0.6907\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.6940 - loss: 0.7589\n",
      "Test Accuracy: 0.6907\n"
     ]
    }
   ],
   "source": [
    "# Build the CNN model\n",
    "model = Sequential()\n",
    "\n",
    "# Add convolutional layers\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(128, 128, 3)))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# Flatten the data and add dense layers\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "# Output layer with a sigmoid activation for binary classification\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=Adam(), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(X_train, y_train_encoded, epochs=10, batch_size=32, validation_data=(X_test, y_test_encoded))\n",
    "\n",
    "# Print the training and validation accuracy after training\n",
    "print(f\"Final Training Accuracy: {history.history['accuracy'][-1]:.4f}\")\n",
    "print(f\"Final Validation Accuracy: {history.history['val_accuracy'][-1]:.4f}\")\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "test_loss, test_acc = model.evaluate(X_test, y_test_encoded)\n",
    "print(f\"Test Accuracy: {test_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "test accuracy pretty bad :( --> overfitting again\n",
    "\n",
    "ideas to fix overfitting\n",
    "- increase regularization\n",
    "- data augmentation? -- rotations, flips, zooms\n",
    "- reduce model complexity\n",
    "- early stopping\n",
    "- different learning rate\n",
    "- external data\n",
    "- cross val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try gridsearch later??"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN with everything?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'Kelly-Image91.png'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[41], line 30\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39marray(images)\n\u001b[1;32m     29\u001b[0m \u001b[38;5;66;03m# Assuming the images are stored in the file paths in the 'Image_Name' column\u001b[39;00m\n\u001b[0;32m---> 30\u001b[0m X_image_train \u001b[38;5;241m=\u001b[39m \u001b[43mload_and_preprocess_images\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeatures_df\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloc\u001b[49m\u001b[43m[\u001b[49m\u001b[43mX_train\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mImage_Name\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     31\u001b[0m X_image_test \u001b[38;5;241m=\u001b[39m load_and_preprocess_images(features_df\u001b[38;5;241m.\u001b[39mloc[X_test\u001b[38;5;241m.\u001b[39mindex, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mImage_Name\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m     33\u001b[0m \u001b[38;5;66;03m# CNN Model for image data\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[41], line 24\u001b[0m, in \u001b[0;36mload_and_preprocess_images\u001b[0;34m(image_paths, image_size)\u001b[0m\n\u001b[1;32m     22\u001b[0m images \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m path \u001b[38;5;129;01min\u001b[39;00m image_paths:\n\u001b[0;32m---> 24\u001b[0m     img \u001b[38;5;241m=\u001b[39m \u001b[43mload_img\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mimage_size\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Load and resize the image\u001b[39;00m\n\u001b[1;32m     25\u001b[0m     img_array \u001b[38;5;241m=\u001b[39m img_to_array(img) \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m255.0\u001b[39m  \u001b[38;5;66;03m# Convert image to array and normalize\u001b[39;00m\n\u001b[1;32m     26\u001b[0m     images\u001b[38;5;241m.\u001b[39mappend(img_array)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/keras/src/utils/image_utils.py:235\u001b[0m, in \u001b[0;36mload_img\u001b[0;34m(path, color_mode, target_size, interpolation, keep_aspect_ratio)\u001b[0m\n\u001b[1;32m    233\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(path, pathlib\u001b[38;5;241m.\u001b[39mPath):\n\u001b[1;32m    234\u001b[0m         path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(path\u001b[38;5;241m.\u001b[39mresolve())\n\u001b[0;32m--> 235\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m    236\u001b[0m         img \u001b[38;5;241m=\u001b[39m pil_image\u001b[38;5;241m.\u001b[39mopen(io\u001b[38;5;241m.\u001b[39mBytesIO(f\u001b[38;5;241m.\u001b[39mread()))\n\u001b[1;32m    237\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'Kelly-Image91.png'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "# Load the CSV containing the features\n",
    "features_df = pd.read_csv('images.csv')\n",
    "\n",
    "\n",
    "# Separate the features and target variable\n",
    "X = features_df.drop(columns=['Image_Name', 'Target', 'Path'])\n",
    "y = features_df['Target']\n",
    "\n",
    "\n",
    "# Train/test split for the features\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, shuffle=True)\n",
    "\n",
    "\n",
    "# Load images from file paths in the 'Path' column\n",
    "def load_and_preprocess_images(image_paths, image_size=(128, 128)):\n",
    "   images = []\n",
    "   for path in image_paths:\n",
    "       try:\n",
    "           img = load_img(path, target_size=image_size)  # Load and resize the image\n",
    "           img_array = img_to_array(img) / 255.0  # Convert image to array and normalize\n",
    "           images.append(img_array)\n",
    "       except FileNotFoundError:\n",
    "           print(f\"File not found: {path}\")\n",
    "           images.append(np.zeros((image_size[0], image_size[1], 3)))  # Add a blank image as a placeholder\n",
    "   return np.array(images)\n",
    "\n",
    "\n",
    "# Assuming the images are stored in the file paths in the 'Path' column\n",
    "X_image_train = load_and_preprocess_images(features_df.loc[X_train.index, 'Path'])\n",
    "X_image_test = load_and_preprocess_images(features_df.loc[X_test.index, 'Path'])\n",
    "\n",
    "\n",
    "# CNN Model for image data\n",
    "model = Sequential()\n",
    "\n",
    "\n",
    "# Add convolutional layers\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(128, 128, 3)))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "\n",
    "# Flatten the data and add dense layers\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "\n",
    "# Output layer with a sigmoid activation for binary classification\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(X_image_train, y_train, epochs=10, batch_size=32, validation_data=(X_image_test, y_test))\n",
    "\n",
    "\n",
    "# Print the training and validation accuracy after training\n",
    "print(f\"Final Training Accuracy: {history.history['accuracy'][-1]:.4f}\")\n",
    "print(f\"Final Validation Accuracy: {history.history['val_accuracy'][-1]:.4f}\")\n",
    "\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "test_loss, test_acc = model.evaluate(X_image_test, y_test)\n",
    "print(f\"Test Accuracy: {test_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Has_People</th>\n",
       "      <th>People_Count</th>\n",
       "      <th>Has_Building</th>\n",
       "      <th>Building_Count</th>\n",
       "      <th>Animal_Type</th>\n",
       "      <th>Animal_Subtype</th>\n",
       "      <th>Is_Landscape_Nature</th>\n",
       "      <th>Has_BoardGames</th>\n",
       "      <th>Has_Road_Pathway</th>\n",
       "      <th>Is_Light_Dark</th>\n",
       "      <th>Is_Close_Far</th>\n",
       "      <th>Is_Straight_On</th>\n",
       "      <th>Has_Horizon</th>\n",
       "      <th>Orientation</th>\n",
       "      <th>Is_Sunrise_Sunset</th>\n",
       "      <th>Has_Tent_Campfire</th>\n",
       "      <th>Has_Food</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>460</th>\n",
       "      <td>460</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>220</th>\n",
       "      <td>220</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>234</th>\n",
       "      <td>234</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>357</th>\n",
       "      <td>357</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>106</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>270</th>\n",
       "      <td>270</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>348</th>\n",
       "      <td>348</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>435</th>\n",
       "      <td>435</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>102</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>388 rows × 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0  Has_People  People_Count  Has_Building  Building_Count  \\\n",
       "460         460           1             1             0               0   \n",
       "25           25           0             0             0               0   \n",
       "220         220           0             0             1               1   \n",
       "234         234           0             0             1               1   \n",
       "357         357           1             1             1               1   \n",
       "..          ...         ...           ...           ...             ...   \n",
       "106         106           1             6             0               0   \n",
       "270         270           0             0             0               0   \n",
       "348         348           1             2             0               0   \n",
       "435         435           1             2             0               0   \n",
       "102         102           0             0             1               1   \n",
       "\n",
       "     Animal_Type  Animal_Subtype  Is_Landscape_Nature  Has_BoardGames  \\\n",
       "460            0               0                    0               0   \n",
       "25             0               0                    1               0   \n",
       "220            0               0                    1               0   \n",
       "234            0               0                    0               0   \n",
       "357            1               2                    0               0   \n",
       "..           ...             ...                  ...             ...   \n",
       "106            0               0                    0               0   \n",
       "270            0               0                    0               0   \n",
       "348            0               0                    1               0   \n",
       "435            0               0                    0               1   \n",
       "102            0               0                    1               0   \n",
       "\n",
       "     Has_Road_Pathway  Is_Light_Dark  Is_Close_Far  Is_Straight_On  \\\n",
       "460                 0              1             1               0   \n",
       "25                  0              0             0               0   \n",
       "220                 0              0             0               0   \n",
       "234                 0              0             0               1   \n",
       "357                 0              1             1               0   \n",
       "..                ...            ...           ...             ...   \n",
       "106                 0              1             1               0   \n",
       "270                 0              1             1               0   \n",
       "348                 0              1             1               0   \n",
       "435                 0              1             1               0   \n",
       "102                 0              0             0               0   \n",
       "\n",
       "     Has_Horizon  Orientation  Is_Sunrise_Sunset  Has_Tent_Campfire  Has_Food  \n",
       "460            0            1                  0                  0         0  \n",
       "25             1            0                  0                  0         0  \n",
       "220            1            0                  0                  0         0  \n",
       "234            1            0                  0                  0         0  \n",
       "357            0            1                  0                  0         0  \n",
       "..           ...          ...                ...                ...       ...  \n",
       "106            0            0                  0                  0         0  \n",
       "270            0            1                  0                  0         0  \n",
       "348            1            0                  0                  0         0  \n",
       "435            0            0                  0                  0         0  \n",
       "102            1            0                  0                  0         0  \n",
       "\n",
       "[388 rows x 18 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import keras_tuner as kt\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "\n",
    "# Function to build the model with hyperparameters\n",
    "def build_model(hp):\n",
    "   model = Sequential()\n",
    "\n",
    "\n",
    "   # Convolutional layers with hyperparameters for filters and kernel size\n",
    "   model.add(Conv2D(\n",
    "       hp.Int('filters1', min_value=32, max_value=128, step=32),\n",
    "       (3, 3),\n",
    "       activation='relu',\n",
    "       input_shape=(128, 128, 3)\n",
    "   ))\n",
    "   model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "  \n",
    "   model.add(Conv2D(\n",
    "       hp.Int('filters2', min_value=64, max_value=256, step=64),\n",
    "       (3, 3),\n",
    "       activation='relu'\n",
    "   ))\n",
    "   model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "  \n",
    "   # Flatten and Dense layers with hyperparameters\n",
    "   model.add(Flatten())\n",
    "   model.add(Dense(\n",
    "       hp.Int('dense_units', min_value=64, max_value=256, step=64),\n",
    "       activation='relu'\n",
    "   ))\n",
    "   model.add(Dropout(hp.Float('dropout_rate', min_value=0.2, max_value=0.5, step=0.1)))\n",
    "  \n",
    "   # Output layer with sigmoid activation for binary classification\n",
    "   model.add(Dense(1, activation='sigmoid'))\n",
    "  \n",
    "   # Compile the model with a hyperparameter for learning rate\n",
    "   model.compile(\n",
    "       optimizer=Adam(learning_rate=hp.Float('learning_rate', min_value=1e-5, max_value=1e-2, sampling='log')),\n",
    "       loss='binary_crossentropy',\n",
    "       metrics=['accuracy']\n",
    "   )\n",
    "  \n",
    "   return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate a RandomSearch tuner with the model-building function\n",
    "tuner = kt.RandomSearch(\n",
    "   build_model,\n",
    "   objective='val_accuracy',\n",
    "   max_trials=5,  # Number of different combinations to test\n",
    "   executions_per_trial=3,  # Number of times to train the model with each combination\n",
    "   directory='my_dir',  # Directory to save the search results\n",
    "   project_name='image_classification'\n",
    ")\n",
    "\n",
    "\n",
    "# Search for the best hyperparameters\n",
    "tuner.search(X_image_train, y_train_encoded, epochs=10, batch_size=32, validation_data=(X_image_test, y_test_encoded))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the best hyperparameters\n",
    "best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "print(f\"Best Hyperparameters: {best_hps.values}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the model with the best hyperparameters\n",
    "model = tuner.hypermodel.build(best_hps)\n",
    "\n",
    "\n",
    "# Train the model with the best hyperparameters\n",
    "history = model.fit(X_image_train, y_train_encoded, epochs=10, batch_size=32, validation_data=(X_image_test, y_test_encoded))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss, test_acc = model.evaluate(X_image_test, y_test_encoded)\n",
    "print(f\"Test Accuracy: {test_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a little better, but can still improve\n",
    "\n",
    "- regularization\n",
    "- more epochs, lower learning rate?\n",
    "- cv?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
